{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# F1 Analytics\n",
    "Data Pipeline project by Elina Yancheva and Vladimir Stoyanov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "circuits = pd.read_csv('data/circuits.csv')\n",
    "constructor_results = pd.read_csv('data/constructor_results.csv')\n",
    "constructor_standings = pd.read_csv('data/constructor_standings.csv')\n",
    "constructors = pd.read_csv('data/constructors.csv')\n",
    "driver_standings = pd.read_csv('data/driver_standings.csv')\n",
    "drivers = pd.read_csv('data/drivers.csv')\n",
    "lap_times = pd.read_csv('data/lap_times.csv')\n",
    "pit_stops = pd.read_csv('data/pit_stops.csv')\n",
    "qualifying = pd.read_csv('data/qualifying.csv')\n",
    "races = pd.read_csv('data/races.csv')\n",
    "results = pd.read_csv('data/results.csv')\n",
    "seasons = pd.read_csv('data/seasons.csv')\n",
    "sprint_results = pd.read_csv('data/sprint_results.csv')\n",
    "status = pd.read_csv('data/status.csv')\n",
    "\n",
    "tables = {\n",
    "    'circuits': circuits,\n",
    "    'constructor_results': constructor_results,\n",
    "    'constructor_standings': constructor_standings,\n",
    "    'constructors': constructors,\n",
    "    'driver_standings': driver_standings,\n",
    "    'drivers': drivers,\n",
    "    'lap_times': lap_times,\n",
    "    'pit_stops': pit_stops,\n",
    "    'qualifying': qualifying,\n",
    "    'races': races,\n",
    "    'results': results,\n",
    "    'seasons': seasons,\n",
    "    'sprint_results': sprint_results,\n",
    "    'status': status\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Key relationships in the F1 dataset:\n",
    "\n",
    "- races is our central table, containing information about each race event (1,125 races)\n",
    "- drivers (859 entries) and constructors (212 teams) are our main entities\n",
    "- results (26,519 entries) connects races, drivers, and constructors with race outcomes\n",
    "- lap_times (575,029 entries) and pit_stops (10,990 entries) provide detailed information about each race and driver\n",
    "- qualifying (10,254 entries) and sprint_results (300 entries) cover pre-race events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def analyze_dataset(df, name):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Analysis for {name} dataset\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    print(\"\\n Basic Information:\")\n",
    "    print(f\"Number of rows: {df.shape[0]}\")\n",
    "    print(f\"Number of columns: {df.shape[1]}\")\n",
    "    \n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_percentages = (missing_values / len(df)) * 100\n",
    "    if missing_values.sum() != 0:\n",
    "        print(\"\\n Missing Values Analysis:\")\n",
    "        for col, missing in missing_values.items():\n",
    "            if missing > 0:\n",
    "                print(f\"{col}: {missing} missing values ({missing_percentages[col]:.2f}%)\")\n",
    "    \n",
    "    duplicates = df.duplicated().sum()\n",
    "    if duplicates > 0:\n",
    "        print(f\"\\n Duplicate Rows: {duplicates}\")\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "datasets = {\n",
    "    'circuits': circuits,\n",
    "    'constructor_results': constructor_results,\n",
    "    'constructor_standings': constructor_standings,\n",
    "    'constructors': constructors,\n",
    "    'driver_standings': driver_standings,\n",
    "    'drivers': drivers,\n",
    "    'lap_times': lap_times,\n",
    "    'pit_stops': pit_stops,\n",
    "    'qualifying': qualifying,\n",
    "    'races': races,\n",
    "    'seasons': seasons,\n",
    "    'sprint_results': sprint_results,\n",
    "    'status': status\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    analyze_dataset(df, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invalid entries search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_f1_data(lap_times_df, results_df, qualifying_df, races_df, pit_stops_df):\n",
    "    print(\"F1 Data Validation Report\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    issues = []\n",
    "    print(\"\\nQualifying Validation:\")\n",
    "    \n",
    "    # Check for drivers with multiple qualifying times in same session\n",
    "    qual_dupes = qualifying_df.groupby(['raceId', 'driverId']).size().reset_index(name='count')\n",
    "    qual_dupes = qual_dupes[qual_dupes['count'] > 1]\n",
    "    if not qual_dupes.empty:\n",
    "        issues.append(f\"Found {len(qual_dupes)} duplicate qualifying entries\")\n",
    "    else:\n",
    "        print(\"No duplicate qualifying entries found!\")\n",
    "    \n",
    "    print(\"\\nRace Schedule Validation:\")\n",
    "    \n",
    "    # Check for races scheduled on same date\n",
    "    race_dates = races_df.groupby('date').size().reset_index(name='count')\n",
    "    date_clashes = race_dates[race_dates['count'] > 1]\n",
    "    if not date_clashes.empty:\n",
    "        issues.append(f\"Found {len(date_clashes)} date clashes in race schedule\")\n",
    "    else:\n",
    "        print(\"No date clashes found!\")\n",
    "    \n",
    "    print(\"\\nValidation Summary:\")\n",
    "    if issues:\n",
    "        print(f\"\\nFound {len(issues)} types of data issues:\")\n",
    "        for issue in issues:\n",
    "            print(f\"- {issue}\")\n",
    "    else:\n",
    "        print(\"\\nNo major data issues found!\")\n",
    "    \n",
    "    return issues\n",
    "\n",
    "issues = validate_f1_data(lap_times, results, qualifying, races, pit_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_lap_times(lap_times_df, races_df, drivers_df):\n",
    "    print(\"\\nLap Times Validation:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Check for zero or negative lap times\n",
    "    zero_laps = lap_times_df[lap_times_df['milliseconds'] <= 0]\n",
    "    if not zero_laps.empty:\n",
    "        issues.append(f\"Found {len(zero_laps)} zero or negative lap times\")\n",
    "    else: \n",
    "        print(\"No zero or negative lap times found\")\n",
    "\n",
    "    lap_times_df['minutes'] = lap_times_df['milliseconds'] / (1000 * 60)\n",
    "    \n",
    "    slow_laps = lap_times_df[lap_times_df['minutes'] > 5].copy()\n",
    "    \n",
    "    if not slow_laps.empty:\n",
    "        # Group slow laps by race and nearby laps (within Â±2 laps)\n",
    "        # When a red flag or safety car occurs, drivers might be on different laps\n",
    "        race_incidents = []\n",
    "        for race_id in slow_laps['raceId'].unique():\n",
    "            race_slow_laps = slow_laps[slow_laps['raceId'] == race_id]\n",
    "            \n",
    "            for _, incident_lap in race_slow_laps.iterrows():\n",
    "                nearby_laps = race_slow_laps[\n",
    "                    (race_slow_laps['lap'] >= incident_lap['lap'] - 2) & \n",
    "                    (race_slow_laps['lap'] <= incident_lap['lap'] + 2)\n",
    "                ]\n",
    "                \n",
    "                if len(nearby_laps) > 5:  # If many drivers affected in nearby laps\n",
    "                    race_incidents.append({\n",
    "                        'raceId': race_id,\n",
    "                        'lap_range': f\"{nearby_laps['lap'].min()}-{nearby_laps['lap'].max()}\",\n",
    "                        'affected_drivers': len(nearby_laps),\n",
    "                        'avg_time': nearby_laps['minutes'].mean(),\n",
    "                        'laps': sorted(nearby_laps['lap'].unique())\n",
    "                    })\n",
    "        \n",
    "        # Remove duplicates (same incident might be counted multiple times)\n",
    "        unique_incidents = []\n",
    "        processed_races = set()\n",
    "        \n",
    "        for incident in race_incidents:\n",
    "            if incident['raceId'] not in processed_races:\n",
    "                unique_incidents.append(incident)\n",
    "                processed_races.add(incident['raceId'])\n",
    "        \n",
    "        # Identify legitimate vs suspicious slow laps\n",
    "        legitimate_races = {incident['raceId'] for incident in unique_incidents}\n",
    "        legitimate_slow = slow_laps[slow_laps['raceId'].isin(legitimate_races)]\n",
    "        suspicious_slow = slow_laps[~slow_laps['raceId'].isin(legitimate_races)]\n",
    "        \n",
    "        legitimate_slow = legitimate_slow.merge(\n",
    "            races_df[['raceId', 'name', 'year']], \n",
    "            on='raceId'\n",
    "        ).merge(\n",
    "            drivers_df[['driverId', 'forename', 'surname']], \n",
    "            on='driverId'\n",
    "        )\n",
    "        \n",
    "        suspicious_slow = suspicious_slow.merge(\n",
    "            races_df[['raceId', 'name', 'year']], \n",
    "            on='raceId'\n",
    "        ).merge(\n",
    "            drivers_df[['driverId', 'forename', 'surname']], \n",
    "            on='driverId'\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFound {len(slow_laps)} lap times longer than 5 minutes\")\n",
    "        print(f\"- {len(legitimate_slow)} likely due to red flags/safety car\")\n",
    "        print(f\"- {len(suspicious_slow)} potentially suspicious\\n\")\n",
    "        \n",
    "        if unique_incidents:\n",
    "            print(\"Probable red flag/safety car incidents:\")\n",
    "            for incident in unique_incidents:\n",
    "                race_info = races_df[races_df['raceId'] == incident['raceId']].iloc[0]\n",
    "                print(f\"\\nRace: {race_info['name']} {race_info['year']}\")\n",
    "                print(f\"Lap range: {incident['lap_range']}\")\n",
    "                print(f\"Affected drivers: {incident['affected_drivers']}\")\n",
    "                print(f\"Average lap time: {incident['avg_time']:.2f} minutes\")\n",
    "                print(f\"Affected laps: {incident['laps']}\")\n",
    "        \n",
    "        if not suspicious_slow.empty:\n",
    "            print(\"\\nSuspicious individual slow laps:\")\n",
    "            for _, lap in suspicious_slow.iterrows():\n",
    "                print(f\"Race: {lap['name']} {lap['year']}, \"\n",
    "                      f\"Driver: {lap['forename']} {lap['surname']}, \"\n",
    "                      f\"Lap: {lap['lap']}, \"\n",
    "                      f\"Time: {lap['minutes']:.2f} minutes\")\n",
    "    \n",
    "    return legitimate_slow, suspicious_slow\n",
    "\n",
    "legitimate_slow_laps, suspicious_slow_laps = validate_lap_times(lap_times, races, drivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lap Times Validation:\n",
    "------------------------------\n",
    "\n",
    "Found 692 lap times longer than 5 minutes\n",
    "- 608 likely due to red flags/safety car\n",
    "- 84 potentially suspicious\n",
    "\n",
    "Based on the analysis of Formula 1 lap times, there were 692 laps identified as longer than 5 minutes, with 608 of these explained by red flags or safety car periods (which force drivers to slow down significantly), as evidenced by multiple drivers having similarly long lap times during those specific race laps. The remaining 84 \"suspicious\" individual slow laps, while initially flagged as potential anomalies, appear to be legitimate race incidents (like pit stops, mechanical issues, or on-track incidents) rather than data errors, which is supported by Google fact-checking of several cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, df in tables.items():\n",
    "    print(f\"\\n{name} dataset:\")\n",
    "    display(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_performance_metrics():\n",
    "    \"\"\"\n",
    "    Creates summary statistics and performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    driver_season_stats = results.merge(races[['raceId', 'year']], on='raceId')\n",
    "    invalid_position = driver_season_stats[driver_season_stats['position'] == '\\\\N']\n",
    "    print(\"\\nDNFs with reasons:\")\n",
    "    display(invalid_position.merge(status, on='statusId')[['raceId', 'year', 'driverId', 'position', 'status']])\n",
    "    \n",
    "    # count DNFs(Did Not Finish)\n",
    "    dnf_count = invalid_position.groupby(['year', 'driverId']).agg({'position': 'count'}).reset_index().rename(columns={'position': 'dnf_count'})\n",
    "    \n",
    "    # Filter valid entries and convert datatypes\n",
    "    driver_season_stats = driver_season_stats[\n",
    "        (driver_season_stats['position'] != '\\\\N') & \n",
    "        (driver_season_stats['milliseconds'] != '\\\\N')\n",
    "    ]\n",
    "    driver_season_stats['position'] = driver_season_stats['position'].astype(int)\n",
    "    driver_season_stats['points'] = driver_season_stats['points'].astype(float)\n",
    "    driver_season_stats['milliseconds'] = driver_season_stats['milliseconds'].astype(float)\n",
    "    \n",
    "    # Driver performance by season\n",
    "    driver_season_summary = driver_season_stats.groupby(['year', 'driverId']).agg({\n",
    "        'points': 'sum',\n",
    "        'position': ['mean', 'min'],\n",
    "        'milliseconds': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "    \n",
    "    driver_season_summary.columns = ['year', 'driverId', 'total_points', \n",
    "                                   'avg_position', 'best_position',\n",
    "                                   'avg_race_time', 'race_time_std']\n",
    "    \n",
    "    # Now merge with DNF counts\n",
    "    driver_season_summary = driver_season_summary.merge(dnf_count, on=['year', 'driverId'], how='left').fillna(0)\n",
    "    driver_season_summary = driver_season_summary.merge(drivers[['driverId', 'forename', 'surname']], on='driverId').drop('driverId', axis=1)\n",
    "    \n",
    "    # Constructor performance trends\n",
    "    constructor_trends = results.merge(races[['raceId', 'year']], on='raceId')\n",
    "    constructor_summary = constructor_trends.groupby(['year', 'constructorId']).agg({\n",
    "        'points': 'sum',\n",
    "        'laps': 'sum'\n",
    "    }).reset_index()\n",
    "    constructor_summary = constructor_summary.merge(constructors[['constructorId', 'name']], on='constructorId').drop('constructorId', axis=1)\n",
    "    \n",
    "    return {\n",
    "        'driver_season_stats': driver_season_summary,\n",
    "        'constructor_trends': constructor_summary\n",
    "    }\n",
    "\n",
    "for k, a in aggregate_performance_metrics().items():\n",
    "    print(f\"\\n{k}:\")\n",
    "    display(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_results = results.merge(races[['raceId', 'year']], on='raceId')\n",
    "race_results = race_results.merge(constructors[['constructorId', 'name']], on='constructorId')\n",
    "\n",
    "# average race time per year across all constructors\n",
    "race_times = race_results[race_results['milliseconds'] != '\\\\N'].copy()\n",
    "race_times['hours'] = race_times['milliseconds'].astype(float) / (1000 * 60 * 60)  \n",
    "\n",
    "yearly_times = race_times.groupby('year')['hours'].agg(['mean', 'std', 'count']).reset_index()\n",
    "yearly_times = yearly_times[yearly_times['count'] > 5]  # Filter years with enough data\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.errorbar(yearly_times['year'], \n",
    "            yearly_times['mean'], \n",
    "            yerr=yearly_times['std'],\n",
    "            alpha=0.5,\n",
    "            capsize=3,\n",
    "            label='Standard deviation')\n",
    "\n",
    "plt.plot(yearly_times['year'], yearly_times['mean'], linewidth=2, label='Average race time')\n",
    "\n",
    "plt.title('Average F1 Race Duration Over the Years')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Race Duration (hours)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "\n",
    "# trend comparison annotations\n",
    "earliest_time = yearly_times.iloc[0]['mean']\n",
    "latest_time = yearly_times.iloc[-1]['mean']\n",
    "time_diff = latest_time - earliest_time\n",
    "\n",
    "print(\"\\nRace Duration Changes:\")\n",
    "print(f\"Average race time in {yearly_times.iloc[0]['year']}: {earliest_time:.2f} hours\")\n",
    "print(f\"Average race time in {yearly_times.iloc[-1]['year']}: {latest_time:.2f} hours\")\n",
    "print(f\"Change: {time_diff:.2f} hours ({(time_diff/earliest_time * 100):.1f}% change)\")\n",
    "\n",
    "# Show fastest and slowest years\n",
    "fastest_year = yearly_times.loc[yearly_times['mean'].idxmin()]\n",
    "slowest_year = yearly_times.loc[yearly_times['mean'].idxmax()]\n",
    "print(f\"\\nFastest average races: {fastest_year['year']} ({fastest_year['mean']:.2f} hours)\")\n",
    "print(f\"Slowest average races: {slowest_year['year']} ({slowest_year['mean']:.2f} hours)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Race Duration and Calendar Evolution:\n",
    "F1 races have become significantly shorter and more standardized since the 1950s, with average race duration dropping from 2.66 hours to 1.58 hours (40.5% reduction). The most extreme year was 1954 with 3.53-hour races, while 1991 saw the shortest average at 1.41 hours. This trend toward shorter races aligns with modern F1's focus on sprint formats and tighter racing. Meanwhile, the calendar has expanded dramatically, from just 7-8 races in the early years to over 20 races today, showing F1's growth into a truly global championship with a much more demanding schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count races per season\n",
    "races_per_year = races.groupby('year').size().reset_index(name='race_count').astype(int)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(races_per_year['year'], races_per_year['race_count'], \n",
    "        marker='o', linewidth=2, markersize=4)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.title('Number of Races per F1 Season')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Races')\n",
    "plt.show()\n",
    "\n",
    "print(f\"First season (1950): {races_per_year.iloc[0]['race_count']} races\")\n",
    "print(f\"Latest season (2024): {races_per_year.iloc[-1]['race_count']} races\")\n",
    "print(f\"Most races: {races_per_year['race_count'].max()} (Year: {races_per_year.loc[races_per_year['race_count'].idxmax(), 'year']})\")\n",
    "print(f\"Fewest races: {races_per_year['race_count'].min()} (Year: {races_per_year.loc[races_per_year['race_count'].idxmin(), 'year']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The races may have been shorthened but luckily their count has been increasing over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drivers comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_driver_stats_comparison(drivers_df, results_df, qualifying_df, races_df):\n",
    "    schumacher_id = drivers_df[\n",
    "        (drivers_df['forename'] == 'Michael') & \n",
    "        (drivers_df['surname'] == 'Schumacher')\n",
    "    ]['driverId'].iloc[0]\n",
    "    \n",
    "    hamilton_id = drivers_df[\n",
    "        (drivers_df['forename'] == 'Lewis') & \n",
    "        (drivers_df['surname'] == 'Hamilton')\n",
    "    ]['driverId'].iloc[0]\n",
    "    \n",
    "    def get_driver_stats(driver_id):\n",
    "        wins = results_df[\n",
    "            (results_df['driverId'] == driver_id) & \n",
    "            (results_df['position'] == '1')\n",
    "        ].shape[0]\n",
    "        \n",
    "        races = results_df[results_df['driverId'] == driver_id].shape[0]\n",
    "        \n",
    "        qualifying_sessions = qualifying_df[qualifying_df['driverId'] == driver_id].shape[0]\n",
    "        \n",
    "        poles = qualifying_df[\n",
    "            (qualifying_df['driverId'] == driver_id) & \n",
    "            (qualifying_df['position'] == 1)\n",
    "        ].shape[0]\n",
    "        \n",
    "        points = results_df[results_df['driverId'] == driver_id]['points'].sum()\n",
    "        \n",
    "        podiums = results_df[\n",
    "            (results_df['driverId'] == driver_id) & \n",
    "            (results_df['position'].isin(['1', '2', '3']))\n",
    "        ].shape[0]\n",
    "        \n",
    "        dnfs = results_df[\n",
    "            (results_df['driverId'] == driver_id) & \n",
    "            (results_df['positionText'] == 'R')\n",
    "        ].shape[0]\n",
    "        \n",
    "        return {\n",
    "            'wins': wins,\n",
    "            'races': races,\n",
    "            'qualifying': qualifying_sessions,\n",
    "            'poles': poles,\n",
    "            'podiums': podiums,\n",
    "            'dnf': dnfs,\n",
    "        }\n",
    "    \n",
    "    schumacher_stats = get_driver_stats(schumacher_id)\n",
    "    hamilton_stats = get_driver_stats(hamilton_id)\n",
    "    \n",
    "    # Print comparison\n",
    "    print(\"Statistical Comparison: Schumacher vs Hamilton\")\n",
    "    print(\"=\" * 50)\n",
    "    for metric in schumacher_stats.keys():\n",
    "        print(f\"{metric.upper():<20} {schumacher_stats[metric]:<15} {hamilton_stats[metric]}\")\n",
    "    \n",
    "    return schumacher_stats, hamilton_stats\n",
    "\n",
    "schumacher_stats, hamilton_stats = get_driver_stats_comparison(\n",
    "    drivers, results, qualifying, races\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_f1_comparison_plots(drivers_df, results_df, qualifying_df, races_df):\n",
    "    schumacher_id = drivers_df[\n",
    "        (drivers_df['forename'] == 'Michael') & \n",
    "        (drivers_df['surname'] == 'Schumacher')\n",
    "    ]['driverId'].iloc[0]\n",
    "    \n",
    "    hamilton_id = drivers_df[\n",
    "        (drivers_df['forename'] == 'Lewis') & \n",
    "        (drivers_df['surname'] == 'Hamilton')\n",
    "    ]['driverId'].iloc[0]\n",
    "    \n",
    "    verstappen_id = drivers_df[\n",
    "        (drivers_df['forename'] == 'Max') & \n",
    "        (drivers_df['surname'] == 'Verstappen')\n",
    "    ]['driverId'].iloc[0]\n",
    "    \n",
    "    plt.style.use('dark_background')\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 14), height_ratios=[3, 1])\n",
    "    \n",
    "    # First plot (Career Statistics)\n",
    "    def get_driver_stats(driver_id):\n",
    "        driver_years = results_df[results_df['driverId'] == driver_id].merge(\n",
    "            races_df[['raceId', 'year']], on='raceId'\n",
    "        )['year'].nunique()\n",
    "        \n",
    "        wins = results_df[\n",
    "            (results_df['driverId'] == driver_id) & \n",
    "            (results_df['position'] == '1')\n",
    "        ].shape[0]\n",
    "        \n",
    "        races = results_df[results_df['driverId'] == driver_id].shape[0]\n",
    "        qualifying_sessions = qualifying_df[qualifying_df['driverId'] == driver_id].shape[0]\n",
    "        \n",
    "        poles = qualifying_df[\n",
    "            (qualifying_df['driverId'] == driver_id) & \n",
    "            (qualifying_df['position'] == 1)\n",
    "        ].shape[0]\n",
    "        \n",
    "        podiums = results_df[\n",
    "            (results_df['driverId'] == driver_id) & \n",
    "            (results_df['position'].isin(['1', '2', '3']))\n",
    "        ].shape[0]\n",
    "        \n",
    "        return {\n",
    "            'YEARS RACING': driver_years,\n",
    "            'WINS': wins,\n",
    "            'RACES': races,\n",
    "            'QUALIFYING': qualifying_sessions,\n",
    "            'POLES': poles,\n",
    "            'PODIUMS': podiums,\n",
    "        }\n",
    "    \n",
    "    # Get career stats\n",
    "    schumacher_stats = get_driver_stats(schumacher_id)\n",
    "    hamilton_stats = get_driver_stats(hamilton_id)\n",
    "    verstappen_stats = get_driver_stats(verstappen_id)\n",
    "    \n",
    "    metrics = list(schumacher_stats.keys())\n",
    "    schumacher_values = list(schumacher_stats.values())\n",
    "    hamilton_values = list(hamilton_stats.values())\n",
    "    verstappen_values = list(verstappen_stats.values())\n",
    "    \n",
    "    # Plot career stats\n",
    "    y_pos = np.arange(len(metrics))\n",
    "    bar_height = 0.25\n",
    "    \n",
    "    ax1.barh(y_pos - bar_height, schumacher_values, bar_height, \n",
    "             label='Schumacher', color='#ff0000')\n",
    "    ax1.barh(y_pos, hamilton_values, bar_height, \n",
    "             label='Hamilton', color='#2dd4bf')\n",
    "    ax1.barh(y_pos + bar_height, verstappen_values, bar_height, \n",
    "             label='Verstappen', color='blue')\n",
    "    \n",
    "    def add_value_labels(values, position, ax):\n",
    "        for i, v in enumerate(values):\n",
    "            ax.text(v, i + position, str(v), \n",
    "                   ha='left', va='center', color='white', fontsize=9)\n",
    "    \n",
    "    add_value_labels(schumacher_values, -bar_height, ax1)\n",
    "    add_value_labels(hamilton_values, 0, ax1)\n",
    "    add_value_labels(verstappen_values, bar_height, ax1)\n",
    "    \n",
    "    ax1.set_yticks(y_pos)\n",
    "    ax1.set_yticklabels(metrics, fontsize=10)\n",
    "    ax1.invert_yaxis()\n",
    "    \n",
    "    # Second plot (Points Comparison)\n",
    "    def get_points_by_season(driver_id):\n",
    "        points_data = results_df[results_df['driverId'] == driver_id].merge(\n",
    "            races_df[['raceId', 'year']], on='raceId'\n",
    "        )\n",
    "        return points_data.groupby('year')['points'].sum().reset_index()\n",
    "    \n",
    "    schumacher_points = get_points_by_season(schumacher_id)\n",
    "    hamilton_points = get_points_by_season(hamilton_id)\n",
    "    verstappen_points = get_points_by_season(verstappen_id)\n",
    "    \n",
    "    ax2.bar(1, schumacher_points['points'].sum(), width=0.8, \n",
    "            color='#ff0000', label='Schumacher')\n",
    "    ax2.bar(2, hamilton_points['points'].sum(), width=0.8, \n",
    "            color='#2dd4bf', label='Hamilton')\n",
    "    ax2.bar(3, verstappen_points['points'].sum(), width=0.8, \n",
    "            color='blue', label='Verstappen')\n",
    "    \n",
    "    for i, points in enumerate([schumacher_points['points'].sum(), \n",
    "                              hamilton_points['points'].sum(), \n",
    "                              verstappen_points['points'].sum()], 1):\n",
    "        ax2.text(i, points, f'{points:,.0f}', \n",
    "                ha='center', va='bottom', color='white', fontsize=10)\n",
    "    \n",
    "    ax2.set_xticks([1, 2, 3])\n",
    "    ax2.set_xticklabels(['Schumacher', 'Hamilton', 'Verstappen'])\n",
    "    ax2.set_title('Total Career Points', pad=20, color='white', fontsize=12)\n",
    "    \n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['bottom'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.set_facecolor('#1f2937')\n",
    "    \n",
    "    fig.patch.set_facecolor('#1f2937')\n",
    "    \n",
    "    ax1.set_title('Career Statistics Comparison', \n",
    "                  pad=20, color='white', fontsize=14)\n",
    "    \n",
    "    ax1.legend(loc='upper right', frameon=False, \n",
    "              fontsize=10, bbox_to_anchor=(1, 1.1))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = create_f1_comparison_plots(drivers, results, qualifying, races)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alonso over the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alonso_seasons_plot(drivers_df, results_df, races_df, constructors_df):\n",
    "    alonso_id = drivers_df[\n",
    "        (drivers_df['forename'] == 'Fernando') & \n",
    "        (drivers_df['surname'] == 'Alonso')\n",
    "    ]['driverId'].iloc[0]\n",
    "    \n",
    "    alonso_results = results_df[results_df['driverId'] == alonso_id].merge(\n",
    "        races_df[['raceId', 'year']], on='raceId'\n",
    "    ).merge(\n",
    "        constructors_df[['constructorId', 'name']], on='constructorId'\n",
    "    )\n",
    "    \n",
    "    # Group by year and team\n",
    "    season_data = alonso_results.groupby(['year', 'name'])['points'].sum().reset_index()\n",
    "    \n",
    "    season_teams = season_data.groupby('year')['name'].agg(list).reset_index()\n",
    "    season_points = season_data.groupby('year')['points'].sum().reset_index()\n",
    "    \n",
    "    season_summary = season_points.merge(season_teams, on='year')\n",
    "    \n",
    "    team_colors = {\n",
    "        'Minardi': '#000000',\n",
    "        'Renault': '#FFD700',\n",
    "        'McLaren': '#FF8C00',\n",
    "        'Ferrari': '#DC143C',\n",
    "        'Alpine F1 Team': '#0090FF',\n",
    "        'Aston Martin': '#006F62'\n",
    "    }\n",
    "    \n",
    "    plt.style.use('dark_background')\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    bars = ax.bar(season_summary['year'], season_summary['points'])\n",
    "    \n",
    "    for bar, teams in zip(bars, season_summary['name']):\n",
    "        if len(teams) == 1:\n",
    "            bar.set_color(team_colors.get(teams[0], '#666666'))\n",
    "        else:\n",
    "            bar.set_color('#666666')  # Multiple teams in one season\n",
    "    \n",
    "    ax.set_facecolor('#1f2937')\n",
    "    fig.patch.set_facecolor('#1f2937')\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    \n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom', color='white')\n",
    "    \n",
    "    plt.xticks(season_summary['year'], rotation=45)\n",
    "    \n",
    "    plt.title(\"Fernando Alonso: Points per Season\", \n",
    "              pad=20, color='white', fontsize=14)\n",
    "    \n",
    "    legend_elements = [plt.Rectangle((0,0),1,1, facecolor=color, label=team)\n",
    "                      for team, color in team_colors.items()]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', \n",
    "             bbox_to_anchor=(1, 1.15), ncol=3, frameon=False)\n",
    "    \n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = create_alonso_seasons_plot(drivers, results, races, constructors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets from pipeline output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "championship_winners = pd.read_parquet('data/championship_winners.parquet')\n",
    "\n",
    "print(\"\\nF1 Championship Winners Dataset:\")\n",
    "print(\"=\" * 50)\n",
    "print(championship_winners.head())\n",
    "\n",
    "print(\"\\nTotal number of championships:\", len(championship_winners))\n",
    "print(\"\\nNumber of championships by driver:\")\n",
    "print(championship_winners['driver_name'].value_counts().head())\n",
    "print(\"\\nNumber of championships by nationality:\")\n",
    "print(championship_winners['nationality'].value_counts().head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constructor_champions = pd.read_parquet('data/constructor_champions.parquet')\n",
    "\n",
    "print(\"\\nF1 Constructor Championship Winners Dataset:\")\n",
    "print(\"=\" * 50)\n",
    "print(constructor_champions.head())\n",
    "\n",
    "print(\"\\nTotal number of championships:\", len(constructor_champions))\n",
    "print(\"\\nNumber of championships by constructor:\")\n",
    "print(constructor_champions['name'].value_counts().head())\n",
    "print(\"\\nNumber of championships by nationality:\")\n",
    "print(constructor_champions['nationality'].value_counts().head())\n",
    "\n",
    "most_recent = constructor_champions.iloc[-1]\n",
    "print(f\"\\nMost recent constructor champion ({most_recent['year']}): {most_recent['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_championships_by_nationality():\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "    constructor_counts = constructor_champions['nationality'].value_counts()\n",
    "    \n",
    "    fig1, ax1 = plt.subplots(figsize=(12, 8))\n",
    "    patches1, texts1, autotexts1 = ax1.pie(\n",
    "        constructor_counts,\n",
    "        labels=constructor_counts.index,\n",
    "        autopct=lambda pct: f'{pct:.1f}%\\n({int(pct/100.*sum(constructor_counts))})',\n",
    "        colors=['#FF0000' if nat == 'Italian' else f'#{hash(nat) % 0xFFFFFF:06x}' for nat in constructor_counts.index],\n",
    "        startangle=90,\n",
    "        labeldistance=1.1,  # Move labels further out\n",
    "        pctdistance=0.75,   # Move percentages closer to edge\n",
    "        explode=[0.05] * len(constructor_counts)  # Separate slices\n",
    "    )\n",
    "    plt.setp(autotexts1, size=9, weight=\"bold\", color='white')\n",
    "    plt.setp(texts1, size=10, color='white')\n",
    "    ax1.set_title('Constructor Championships by Nationality', pad=20, size=14)\n",
    "    fig1.patch.set_facecolor('#1f2937')\n",
    "    ax1.set_facecolor('#1f2937')\n",
    "    plt.show()\n",
    "\n",
    "plot_championships_by_nationality()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_position_gains(qualifying_df, results_df, drivers_df, races_df):\n",
    "    position_changes = qualifying_df.merge(\n",
    "        results_df[['raceId', 'driverId', 'positionOrder']], \n",
    "        on=['raceId', 'driverId']\n",
    "    )\n",
    "    \n",
    "    position_changes = position_changes.merge(\n",
    "        drivers_df[['driverId', 'forename', 'surname']], \n",
    "        on='driverId'\n",
    "    )\n",
    "    \n",
    "    position_changes = position_changes.merge(\n",
    "        races_df[['raceId', 'year', 'name']], \n",
    "        on='raceId'\n",
    "    )\n",
    "    \n",
    "    # Convert qualifying position to numeric\n",
    "    position_changes['position_q'] = pd.to_numeric(position_changes['position'])\n",
    "    \n",
    "    # Calculate position gain (qualifying position - finish position)\n",
    "    position_changes['positions_gained'] = position_changes['position_q'] - position_changes['positionOrder']\n",
    "    \n",
    "    gains = position_changes[[\n",
    "        'year', 'name', 'forename', 'surname', \n",
    "        'position_q', 'positionOrder', 'positions_gained'\n",
    "    ]].copy()\n",
    "    gains['driver_name'] = gains['forename'] + ' ' + gains['surname']\n",
    "    \n",
    "    # Filter for only positive gains (moving up the order)\n",
    "    gains = gains[gains['positions_gained'] > 0]\n",
    "    \n",
    "    gains = gains.sort_values('positions_gained', ascending=False)\n",
    "    top_10_gains = gains.head(10)\n",
    "    \n",
    "    result = top_10_gains[[\n",
    "        'driver_name', 'year', 'name', \n",
    "        'position_q', 'positionOrder', 'positions_gained'\n",
    "    ]].rename(columns={\n",
    "        'name': 'race',\n",
    "        'position_q': 'qualifying_position',\n",
    "        'positionOrder': 'finishing_position'\n",
    "    })\n",
    "    \n",
    "    return result\n",
    "\n",
    "top_gains = find_best_position_gains(qualifying, results, drivers, races)\n",
    "\n",
    "print(\"\\nTop 10 Greatest Comebacks in F1 History (Qualifying to Race Finish)\")\n",
    "print(\"=\" * 80)\n",
    "display(top_gains.sort_values(by=['positions_gained', 'year'], ascending=False) .head(n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_position_gains(qualifying_df, results_df, drivers_df, races_df):\n",
    "    # Get only top 5 from our previous function\n",
    "    top_gains = find_best_position_gains(qualifying_df, results_df, drivers_df, races_df).head(5)\n",
    "    \n",
    "    plt.style.use('dark_background')\n",
    "    fig, ax = plt.subplots(figsize=(10, 6), dpi=100)\n",
    "    \n",
    "    start_color = '#ff6b6b'  # Red for qualifying\n",
    "    end_color = '#4ecdc4'    # Green for finish\n",
    "    line_color = '#666666'   # Grey for connecting lines\n",
    "    \n",
    "    x_positions = [0, 1]  # 0 for qualifying, 1 for race finish\n",
    "    \n",
    "    for idx, row in top_gains.iterrows():\n",
    "        # Plot lines between qualifying and race positions\n",
    "        plt.plot(x_positions, \n",
    "                [row['qualifying_position'], row['finishing_position']], \n",
    "                color=line_color, \n",
    "                label=f\"{row['driver_name'].split(' ')[-1]} ({row['year']})\")\n",
    "        \n",
    "        plt.scatter(0, row['qualifying_position'], color=start_color, s=100, zorder=5)\n",
    "        plt.scatter(1, row['finishing_position'], color=end_color, s=100, zorder=5)\n",
    "        \n",
    "        plt.text(1.1, row['finishing_position'], \n",
    "                f\"+{int(row['positions_gained'])}\", \n",
    "                color=end_color, \n",
    "                va='center')\n",
    "\n",
    "    ax.set_xlim(-0.2, 1.5)\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(['Qualifying', 'Race Finish'])\n",
    "    \n",
    "    # Set y-axis (reversed, as P1 should be at top)\n",
    "    max_position = max(top_gains['qualifying_position'].max(), top_gains['finishing_position'].max())\n",
    "    ax.set_ylim(max_position + 1, 0)\n",
    "    ax.set_yticks(range(1, max_position + 1))\n",
    "    ax.set_yticklabels([f'P{pos}' for pos in range(1, max_position + 1)])\n",
    "    \n",
    "    plt.title('Top 5 Greatest F1 Position Gains', pad=20, fontsize=12)\n",
    "    plt.legend(loc='center right', bbox_to_anchor=(1.3, 0.5), frameon=False)\n",
    "    \n",
    "    ax.set_facecolor('#1f2937')\n",
    "    fig.patch.set_facecolor('#1f2937')\n",
    "    ax.grid(True, axis='y', linestyle='--', alpha=0.2)\n",
    "    \n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plot_top_position_gains(qualifying, results, drivers, races)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Race prediction model \n",
    "Random forest model trained to predict finish position based on several factors - e.g. grid position, qualifying time, fastest lap time, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_race_prediction_data(qualifying_df, results_df, drivers_df, constructors_df, races_df):\n",
    "    race_data = results_df.merge(\n",
    "        races_df[['raceId', 'circuitId', 'year']], \n",
    "        on='raceId'\n",
    "    )\n",
    "    \n",
    "    race_data = race_data.merge(\n",
    "        qualifying_df[['raceId', 'driverId', 'position']], \n",
    "        on=['raceId', 'driverId'],\n",
    "        suffixes=('_finish', '_quali')\n",
    "    )\n",
    "    \n",
    "    race_data = race_data.merge(drivers_df[['driverId', 'nationality']], on='driverId')\n",
    "    race_data = race_data.merge(constructors_df[['constructorId', 'nationality']], \n",
    "                               on='constructorId', suffixes=('_driver', '_constructor'))\n",
    "    \n",
    "    def create_historical_features(df):\n",
    "        df = df.sort_values('year')\n",
    "        \n",
    "        # Last 3 races performance\n",
    "        df['last_3_avg_position'] = df.groupby('driverId')['positionOrder'].transform(\n",
    "            lambda x: x.shift().rolling(3).mean()\n",
    "        )\n",
    "        \n",
    "        # Constructor's last 3 races\n",
    "        df['constructor_last_3_avg'] = df.groupby('constructorId')['positionOrder'].transform(\n",
    "            lambda x: x.shift().rolling(3).mean()\n",
    "        )\n",
    "        \n",
    "        df['track_history_avg'] = df.groupby(['driverId', 'circuitId'])['positionOrder'].transform(\n",
    "            lambda x: x.shift().mean()\n",
    "        )\n",
    "        \n",
    "        # Qualifying performance vs race performance ratio\n",
    "        df['quali_race_ratio'] = df['position_quali'] / df['positionOrder']\n",
    "        \n",
    "        # Driver's performance at this circuit\n",
    "        df['circuit_win_rate'] = df.groupby(['driverId', 'circuitId'])['positionOrder'].transform(\n",
    "            lambda x: (x.shift() == 1).mean()\n",
    "        )\n",
    "        \n",
    "        # Constructor's performance at this circuit\n",
    "        df['constructor_circuit_avg'] = df.groupby(['constructorId', 'circuitId'])['positionOrder'].transform(\n",
    "            lambda x: x.shift().mean()\n",
    "        )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    features_df = race_data.pipe(create_historical_features)\n",
    "    \n",
    "    X = features_df[[\n",
    "        'grid',\n",
    "        'position_quali',\n",
    "        'last_3_avg_position',\n",
    "        'constructor_last_3_avg',\n",
    "        'track_history_avg',\n",
    "        'quali_race_ratio',\n",
    "        'circuit_win_rate',\n",
    "        'constructor_circuit_avg'\n",
    "    ]].fillna(-1)\n",
    "    \n",
    "    y = features_df['positionOrder']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def create_race_prediction_model():\n",
    "    X, y = prepare_race_prediction_data(qualifying, results, drivers, constructors, races)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_rmse = np.sqrt(-cv_scores)\n",
    "    \n",
    "    print(\"Test Set Results:\")\n",
    "    print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    print(f\"\\nCross-validation RMSE: {cv_rmse.mean():.2f} (+/- {cv_rmse.std() * 2:.2f})\")\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nFeature Importance:\")\n",
    "    print(feature_importance)\n",
    "    \n",
    "    return model, feature_importance\n",
    "\n",
    "model, feature_importance = create_race_prediction_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_race_prediction_analysis(model, feature_importance):\n",
    "    X, y = prepare_race_prediction_data(qualifying, results, drivers, constructors, races)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    plt.style.use('dark_background')\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    ax1 = plt.subplot(2, 2, 1)\n",
    "    feature_importance_plot = feature_importance.copy()\n",
    "    feature_importance_plot['feature'] = feature_importance_plot['feature'].map({\n",
    "        'grid': 'Grid Position',\n",
    "        'position_quali': 'Qualifying Position',\n",
    "        'last_3_avg_position': 'Last 3 Races Avg',\n",
    "        'constructor_last_3_avg': 'Constructor Last 3 Races',\n",
    "        'track_history_avg': 'Track History',\n",
    "        'quali_race_ratio': 'Quali/Race Ratio',\n",
    "        'circuit_win_rate': 'Circuit Win Rate',\n",
    "        'constructor_circuit_avg': 'Constructor at Circuit'\n",
    "    })\n",
    "    \n",
    "    ax1.barh(y=range(len(feature_importance_plot)), \n",
    "             width=feature_importance_plot['importance'],\n",
    "             color='#2dd4bf')\n",
    "    ax1.set_yticks(range(len(feature_importance_plot)))\n",
    "    ax1.set_yticklabels(feature_importance_plot['feature'])\n",
    "    ax1.set_title('Feature Importance in Race Position Prediction', pad=20)\n",
    "    ax1.set_xlabel('Importance Score')\n",
    "    \n",
    "    # predicted vs actual plot\n",
    "    ax2 = plt.subplot(2, 2, 2)\n",
    "    scatter = ax2.scatter(y_test, y_pred, alpha=0.5, color='#2dd4bf')\n",
    "    ax2.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             'r--', lw=2, label='Perfect Prediction')\n",
    "    ax2.set_xlabel('Actual Finish Position')\n",
    "    ax2.set_ylabel('Predicted Finish Position')\n",
    "    ax2.set_title('Predicted vs Actual Finish Positions', pad=20)\n",
    "    ax2.legend()\n",
    "    \n",
    "    \n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.set_facecolor('#1f2937')\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_color('#666666')\n",
    "        ax.grid(True, alpha=0.2)\n",
    "        \n",
    "    fig.patch.set_facecolor('#1f2937')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # position-specific accuracy\n",
    "    print(\"\\nAccuracy by Position Range:\")\n",
    "    position_ranges = [(1,3), (4,10), (11,20)]\n",
    "    for start, end in position_ranges:\n",
    "        mask = (y_test >= start) & (y_test <= end)\n",
    "        if mask.any():\n",
    "            range_mae = mean_absolute_error(y_test[mask], y_pred[mask])\n",
    "            print(f\"\\nPositions {start}-{end}:\")\n",
    "            print(f\"Mean Absolute Error: {range_mae:.2f} positions\")\n",
    "            print(f\"Samples: {mask.sum()}\")\n",
    "    \n",
    "    return fig\n",
    "\n",
    "fig = plot_race_prediction_analysis(model, feature_importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_race_finish(model, driver_scenario):\n",
    "    X_predict = pd.DataFrame([driver_scenario])\n",
    "    \n",
    "    predicted_position = model.predict(X_predict)[0]\n",
    "    \n",
    "    print(\"\\nRace Scenario Analysis:\")\n",
    "    print(\"-\" * 30)\n",
    "    for feature, value in driver_scenario.items():\n",
    "        print(f\"{feature}: {value}\")\n",
    "    \n",
    "    print(f\"\\nPredicted Finish Position: {predicted_position:.1f}\")\n",
    "    \n",
    "    return predicted_position\n",
    "\n",
    "# Let's simulate a top driver starting from P6\n",
    "scenario = {\n",
    "    'grid': 6,  # Starting from P6\n",
    "    'position_quali': 6,  # Qualified P6\n",
    "    'last_3_avg_position': 3.0,  # Average P3 in last 3 races\n",
    "    'constructor_last_3_avg': 2.5,  # Constructor performing well\n",
    "    'track_history_avg': 2.0,  # Historically good at this track\n",
    "    'quali_race_ratio': 1.2,  # Typically improves in race\n",
    "    'circuit_win_rate': 0.3,  # Won 30% of races at this circuit\n",
    "    'constructor_circuit_avg': 2.8  # Constructor typically performs well here\n",
    "}\n",
    "\n",
    "prediction = predict_race_finish(model, scenario)\n",
    "\n",
    "midfield_scenario = {\n",
    "    'grid': 12,  # Starting from P12\n",
    "    'position_quali': 12,\n",
    "    'last_3_avg_position': 10.0,\n",
    "    'constructor_last_3_avg': 9.5,\n",
    "    'track_history_avg': 11.0,\n",
    "    'quali_race_ratio': 0.9,\n",
    "    'circuit_win_rate': 0.0,\n",
    "    'constructor_circuit_avg': 9.5\n",
    "}\n",
    "\n",
    "print(\"\\nMidfield Scenario:\")\n",
    "prediction_midfield = predict_race_finish(model, midfield_scenario)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
